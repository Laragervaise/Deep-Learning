{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import dlc_practical_prologue as prologue\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from models import FNN, FNN_WS, FNN_WS_AUX, FNN_AUX, CNN, CNN_WS_AUX, CNN_WS, CNN_AUX\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "\n",
    "    # Load the data\n",
    "    size = 1000\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(size)\n",
    "\n",
    "    #normalization\n",
    "    #check https://stats.stackexchange.com/questions/174823/\n",
    "    mu, std = train_input.mean(), train_input.std()\n",
    "    train_input, test_input = train_input.sub(mu).div(std), test_input.sub(mu).div(std)\n",
    "\n",
    "    #split the images\n",
    "    train_input1, train_input2 = train_input[:, 0, :, :], train_input[:, 1, :, :] \n",
    "    test_input1, test_input2 = test_input[:, 0, :, :], test_input[:, 1, :, :] \n",
    "\n",
    "    #split the number pairs\n",
    "    train_classes1, train_classes2 = train_classes[:, 0], train_classes[:, 1]\n",
    "    test_classes1, test_classes2 = test_classes[:, 0], test_classes[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param model: a dict encapsulating the model and its properties\n",
    ":param inps1: lhs of image pairs\n",
    ":param inps2: rhs of image pairs\n",
    ":param digits1: classes of inps1 \n",
    ":param digits2: classes of inps2\n",
    ":param targets: final boolean value indicating whether lhs <= rhs\n",
    ":return: a dict encapsulating the model history\n",
    "\"\"\"\n",
    "def train_model(model, inps1, inps2, digits1, digits2, targets):\n",
    "    \n",
    "    epochs = model['nb_epochs']\n",
    "    batch_size = model['batch_size']\n",
    "    criterion = model['criterion']\n",
    "    optimizer = model['optimizer']\n",
    "    mdl = model['model']\n",
    "      \n",
    "    #  a dict to return whatever value we wanna return\n",
    "    #  e.g. loss at each epoch (useful for plotting)\n",
    "    model_history = dict()\n",
    "    \n",
    "    \n",
    "    loss_history = [] #a list to keep track of the losses at each epoch\n",
    "    for e in range(epochs):\n",
    "        train_indices = random.sample(range(inps1.size(0)), batch_size)  # pick a minibatch   \n",
    "        d1, d2, pred = mdl(inps1[train_indices], inps2[train_indices])   # run through the network\n",
    "        pred_loss =  criterion(pred.view(-1, 2), targets[train_indices]) # loss due to boolean value\n",
    "            \n",
    "        #this is where auxillary loss happens depending on the model.\n",
    "        #if a model returns the digit information, it is taken into account in the backprop.\n",
    "        #if there is no digit info only loss we have is the one due to boolean above\n",
    "        if d1 is not None:\n",
    "            pred_loss += criterion(d1.view(-1, 10), digits1[train_indices])\n",
    "            pred_loss += criterion(d2.view(-1, 10), digits2[train_indices])\n",
    "            pred_loss /= 3\n",
    "            \n",
    "        loss = pred_loss.item() #magnitude of the loss\n",
    "        mdl.zero_grad()         #reset the gradients for this epoch\n",
    "        pred_loss.backward()    #calculate the gradients\n",
    "        optimizer.step()        #update the weights\n",
    "            \n",
    "\n",
    "        loss_history.append(loss) #record the loss \n",
    "        \n",
    "    model_history['loss_history'] = loss_history\n",
    "    return model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param model: a dict encapsulating the model and its properties\n",
    ":param inps1: lhs of image pairs\n",
    ":param inps2: rhs of image pairs\n",
    ":param digits1: classes of inps1 \n",
    ":param digits2: classes of inps2\n",
    ":param targets: final boolean value indicating whether lhs <= rhs\n",
    ":return: a triplet indicating the accuracies ordered as (boolean,lhs,rhs)\n",
    "\"\"\"\n",
    "def compute_nb_errors(model, inps1, inps2, digits1, digits2, targets):\n",
    "    n_samples = inps1.shape[0]\n",
    "    \n",
    "    d1,d2,pred = model(inps1, inps2)           # predict the digits + boolean\n",
    "    _, indices = torch.max(pred.view(-1,2), 1) # torch.max returns the max value from the distribution and its corresponding index\n",
    "    acc_target = (sum(indices == targets) / float(n_samples) * 100).item()  #calculate accuracy\n",
    "\n",
    "    acc_d1, acc_d2 = 0, 0\n",
    "    if d1 is not None: #the model returns digits if it makes use of aux loss. in this case we can report the accuracy of predicting the digits.\n",
    "        _, indices1 = torch.max(d1.view(-1,10), 1)\n",
    "        _, indices2 = torch.max(d2.view(-1,10), 1)\n",
    "        acc_d1 += (sum(indices1 == digits1) / float(n_samples) * 100).item()\n",
    "        acc_d2 += (sum(indices2 == digits2) / float(n_samples) * 100).item()\n",
    "    \n",
    "    \n",
    "    return (acc_target, acc_d1, acc_d2)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param model_constructor: constructor for the model\n",
    ":param optimizer_name: 'sgd' or 'adam'\n",
    ":param lr: learning rate\n",
    ":param batch_size: batch_size.\n",
    ":return: an encapsulated model ready for the training\n",
    "\"\"\"\n",
    "def model_selector(model_constructor, optimizer_name, lr, batch_size):\n",
    "    model = dict()\n",
    "    model['model'] = model_constructor()\n",
    "    model['criterion'] = nn.CrossEntropyLoss()\n",
    "    model['nb_epochs'] = 25\n",
    "    model['batch_size'] = batch_size\n",
    "    if(optimizer_name == 'sgd'):\n",
    "        model['optimizer'] = torch.optim.SGD(model['model'].parameters(), lr=lr, momentum=0.9)\n",
    "    elif optimizer_name == 'adam':\n",
    "        model['optimizer'] =  torch.optim.Adam(model['model'].parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param inps1: lhs of image pairs\n",
    ":param inps2: rhs of image pairs\n",
    ":param digits1: classes of inps1 \n",
    ":param digits2: classes of inps2\n",
    ":param targets: final boolean value indicating whether lhs <= rhs\n",
    ":return: a triplet indicating the accuracies ordered as (boolean,lhs,rhs)\n",
    "\"\"\"\n",
    "def cross_val_score(inps1, inps2, digits1, digits2, targets, model_constructor, optimizer_name, lr, batch_size, k_folds=5):\n",
    "    len_train = inps1.shape[0]\n",
    "    indices = [i for i in range(len_train)]\n",
    "    random.seed(8)\n",
    "    random.shuffle(indices)\n",
    "    acc_target, acc_d1, acc_d2  = 0,0,0\n",
    "    for k in range(k_folds):\n",
    "        model = model_selector(model_constructor, optimizer_name, lr, batch_size)  # init the same model\n",
    "        val_indices = indices[k*len_train//k_folds:(k+1)*len_train//k_folds] # 1 validation fold\n",
    "        train_indices = list(set(indices) - set(val_indices))                # k-1 training fold\n",
    "        \n",
    "        #train the model with k-1 training fold\n",
    "        history = train_model(model, inps1[train_indices], inps2[train_indices], digits1[train_indices], digits2[train_indices], targets[train_indices])\n",
    "        \n",
    "        #compute the accuracy on 1 validation fold\n",
    "        accs = compute_nb_errors(model['model'], inps1[val_indices], inps2[val_indices], digits1[val_indices], digits2[val_indices], targets[val_indices])\n",
    "        \n",
    "        acc_target += accs[0]\n",
    "        acc_d1 += accs[1]\n",
    "        acc_d2 += accs[2]\n",
    "        print('fold=', k, ' loss = ', history['loss_history'][-1])\n",
    "    return (acc_target / k_folds, acc_d1 /k_folds, acc_d2 /k_folds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'models.FNN'> 800 0.01 adam\n",
      "fold= 0  loss =  0.5233651995658875\n",
      "fold= 1  loss =  0.5196735858917236\n",
      "fold= 2  loss =  0.5278564691543579\n",
      "fold= 3  loss =  0.5362232327461243\n",
      "fold= 4  loss =  0.5344428420066833\n",
      "74.5 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.011 adam\n",
      "fold= 0  loss =  0.522051990032196\n",
      "fold= 1  loss =  0.5160800814628601\n",
      "fold= 2  loss =  0.5373734831809998\n",
      "fold= 3  loss =  0.5356819033622742\n",
      "fold= 4  loss =  0.5359436869621277\n",
      "74.3 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.012 adam\n",
      "fold= 0  loss =  0.5165899991989136\n",
      "fold= 1  loss =  0.5291900634765625\n",
      "fold= 2  loss =  0.5314457416534424\n",
      "fold= 3  loss =  0.5187000036239624\n",
      "fold= 4  loss =  0.5375038981437683\n",
      "72.8 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.013000000000000001 adam\n",
      "fold= 0  loss =  0.5019742846488953\n",
      "fold= 1  loss =  0.5044704079627991\n",
      "fold= 2  loss =  0.5168421268463135\n",
      "fold= 3  loss =  0.51800936460495\n",
      "fold= 4  loss =  0.533112645149231\n",
      "72.9 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.014 adam\n",
      "fold= 0  loss =  0.5033760070800781\n",
      "fold= 1  loss =  0.5105772018432617\n",
      "fold= 2  loss =  0.5076467990875244\n",
      "fold= 3  loss =  0.5204142332077026\n",
      "fold= 4  loss =  0.5213485956192017\n",
      "74.8 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.015 adam\n",
      "fold= 0  loss =  0.49712619185447693\n",
      "fold= 1  loss =  0.5034817457199097\n",
      "fold= 2  loss =  0.524757981300354\n",
      "fold= 3  loss =  0.5057718753814697\n",
      "fold= 4  loss =  0.5245689153671265\n",
      "73.3 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.016 adam\n",
      "fold= 0  loss =  0.5059364438056946\n",
      "fold= 1  loss =  0.5078831911087036\n",
      "fold= 2  loss =  0.5168288946151733\n",
      "fold= 3  loss =  0.5234588384628296\n",
      "fold= 4  loss =  0.5171926617622375\n",
      "73.0 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.017 adam\n",
      "fold= 0  loss =  0.497384637594223\n",
      "fold= 1  loss =  0.5127911567687988\n",
      "fold= 2  loss =  0.5161248445510864\n",
      "fold= 3  loss =  0.5157290101051331\n",
      "fold= 4  loss =  0.509533166885376\n",
      "72.6 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.018000000000000002 adam\n",
      "fold= 0  loss =  0.49097740650177\n",
      "fold= 1  loss =  0.49873340129852295\n",
      "fold= 2  loss =  0.5093085169792175\n",
      "fold= 3  loss =  0.5115883946418762\n",
      "fold= 4  loss =  0.5012212991714478\n",
      "74.0 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.019 adam\n",
      "fold= 0  loss =  0.4908811151981354\n",
      "fold= 1  loss =  0.5001603960990906\n",
      "fold= 2  loss =  0.502454400062561\n",
      "fold= 3  loss =  0.5074567198753357\n",
      "fold= 4  loss =  0.5042404532432556\n",
      "74.5 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.02 adam\n",
      "fold= 0  loss =  0.4898453652858734\n",
      "fold= 1  loss =  0.502169668674469\n",
      "fold= 2  loss =  0.5085634589195251\n",
      "fold= 3  loss =  0.5112080574035645\n",
      "fold= 4  loss =  0.5394572615623474\n",
      "74.9 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.021 adam\n",
      "fold= 0  loss =  0.49327361583709717\n",
      "fold= 1  loss =  0.5104460120201111\n",
      "fold= 2  loss =  0.5021749138832092\n",
      "fold= 3  loss =  0.5067475438117981\n",
      "fold= 4  loss =  0.5235805511474609\n",
      "73.2 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.022 adam\n",
      "fold= 0  loss =  0.505521297454834\n",
      "fold= 1  loss =  0.49111220240592957\n",
      "fold= 2  loss =  0.507760226726532\n",
      "fold= 3  loss =  0.5139886140823364\n",
      "fold= 4  loss =  0.5025526881217957\n",
      "73.6 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.023 adam\n",
      "fold= 0  loss =  0.49938541650772095\n",
      "fold= 1  loss =  0.49703478813171387\n",
      "fold= 2  loss =  0.5493572950363159\n",
      "fold= 3  loss =  0.49899059534072876\n",
      "fold= 4  loss =  0.508199155330658\n",
      "74.4 0.0 0.0\n",
      "<class 'models.FNN'> 800 0.024 adam\n",
      "fold= 0  loss =  0.5222012996673584\n",
      "fold= 1  loss =  0.5035739541053772\n",
      "fold= 2  loss =  0.5467699766159058\n",
      "fold= 3  loss =  0.505635678768158\n",
      "fold= 4  loss =  0.5128142237663269\n",
      "73.0 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.01 adam\n",
      "fold= 0  loss =  0.5623631477355957\n",
      "fold= 1  loss =  0.5600785613059998\n",
      "fold= 2  loss =  0.5515355467796326\n",
      "fold= 3  loss =  0.5666864514350891\n",
      "fold= 4  loss =  0.5811989307403564\n",
      "74.1 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.011 adam\n",
      "fold= 0  loss =  0.5405882596969604\n",
      "fold= 1  loss =  0.5560920238494873\n",
      "fold= 2  loss =  0.5625553727149963\n",
      "fold= 3  loss =  0.5470425486564636\n",
      "fold= 4  loss =  0.5657123327255249\n",
      "76.3 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.012 adam\n",
      "fold= 0  loss =  0.529635488986969\n",
      "fold= 1  loss =  0.5377612113952637\n",
      "fold= 2  loss =  0.5509259700775146\n",
      "fold= 3  loss =  0.5386443138122559\n",
      "fold= 4  loss =  0.5495706796646118\n",
      "75.4 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.013000000000000001 adam\n",
      "fold= 0  loss =  0.5405668616294861\n",
      "fold= 1  loss =  0.5413805246353149\n",
      "fold= 2  loss =  0.5416794419288635\n",
      "fold= 3  loss =  0.5526355504989624\n",
      "fold= 4  loss =  0.5442852973937988\n",
      "73.3 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.014 adam\n",
      "fold= 0  loss =  0.5491147041320801\n",
      "fold= 1  loss =  0.5347804427146912\n",
      "fold= 2  loss =  0.5533866882324219\n",
      "fold= 3  loss =  0.554309606552124\n",
      "fold= 4  loss =  0.5284742712974548\n",
      "75.2 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.015 adam\n",
      "fold= 0  loss =  0.5311836004257202\n",
      "fold= 1  loss =  0.525651752948761\n",
      "fold= 2  loss =  0.534364640712738\n",
      "fold= 3  loss =  0.5285840034484863\n",
      "fold= 4  loss =  0.5405312180519104\n",
      "75.2 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.016 adam\n",
      "fold= 0  loss =  0.5181137919425964\n",
      "fold= 1  loss =  0.5232433676719666\n",
      "fold= 2  loss =  0.5302609801292419\n",
      "fold= 3  loss =  0.534963846206665\n",
      "fold= 4  loss =  0.5537281632423401\n",
      "75.1 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.017 adam\n",
      "fold= 0  loss =  0.5198001265525818\n",
      "fold= 1  loss =  0.5151942372322083\n",
      "fold= 2  loss =  0.5266955494880676\n",
      "fold= 3  loss =  0.5237144231796265\n",
      "fold= 4  loss =  0.529997706413269\n",
      "76.5 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.018000000000000002 adam\n",
      "fold= 0  loss =  0.5092087984085083\n",
      "fold= 1  loss =  0.5052679181098938\n",
      "fold= 2  loss =  0.5180647373199463\n",
      "fold= 3  loss =  0.5350954532623291\n",
      "fold= 4  loss =  0.5220845937728882\n",
      "74.7 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.019 adam\n",
      "fold= 0  loss =  0.5112855434417725\n",
      "fold= 1  loss =  0.5155971646308899\n",
      "fold= 2  loss =  0.5182363390922546\n",
      "fold= 3  loss =  0.5393098592758179\n",
      "fold= 4  loss =  0.5213966369628906\n",
      "75.2 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.02 adam\n",
      "fold= 0  loss =  0.523520290851593\n",
      "fold= 1  loss =  0.5132437348365784\n",
      "fold= 2  loss =  0.5099108219146729\n",
      "fold= 3  loss =  0.5059292316436768\n",
      "fold= 4  loss =  0.50691819190979\n",
      "74.7 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.021 adam\n",
      "fold= 0  loss =  0.5187724828720093\n",
      "fold= 1  loss =  0.5014655590057373\n",
      "fold= 2  loss =  0.5149355530738831\n",
      "fold= 3  loss =  0.5425711274147034\n",
      "fold= 4  loss =  0.5419214367866516\n",
      "75.4 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.022 adam\n",
      "fold= 0  loss =  0.5069832801818848\n",
      "fold= 1  loss =  0.5170846581459045\n",
      "fold= 2  loss =  0.5080167651176453\n",
      "fold= 3  loss =  0.5282151103019714\n",
      "fold= 4  loss =  0.5141348242759705\n",
      "75.3 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.023 adam\n",
      "fold= 0  loss =  0.5149664878845215\n",
      "fold= 1  loss =  0.5111337900161743\n",
      "fold= 2  loss =  0.5179948210716248\n",
      "fold= 3  loss =  0.526250958442688\n",
      "fold= 4  loss =  0.5628230571746826\n",
      "74.1 0.0 0.0\n",
      "<class 'models.FNN_WS'> 800 0.024 adam\n",
      "fold= 0  loss =  0.5096952319145203\n",
      "fold= 1  loss =  0.5001518130302429\n",
      "fold= 2  loss =  0.5128262042999268\n",
      "fold= 3  loss =  0.5279818773269653\n",
      "fold= 4  loss =  0.5366358757019043\n",
      "75.2 0.0 0.0\n",
      "<class 'models.FNN_WS_AUX'> 800 0.01 adam\n",
      "fold= 0  loss =  1.1390894651412964\n",
      "fold= 1  loss =  1.1411763429641724\n",
      "fold= 2  loss =  1.2037383317947388\n",
      "fold= 3  loss =  1.1440585851669312\n",
      "fold= 4  loss =  1.1416749954223633\n",
      "91.2 87.8 86.5\n",
      "<class 'models.FNN_WS_AUX'> 800 0.011 adam\n",
      "fold= 0  loss =  1.1477669477462769\n",
      "fold= 1  loss =  1.14070463180542\n",
      "fold= 2  loss =  1.1434135437011719\n",
      "fold= 3  loss =  1.2101311683654785\n",
      "fold= 4  loss =  1.1387939453125\n",
      "91.0 88.9 86.8\n",
      "<class 'models.FNN_WS_AUX'> 800 0.012 adam\n",
      "fold= 0  loss =  1.1423221826553345\n",
      "fold= 1  loss =  1.1359177827835083\n",
      "fold= 2  loss =  1.1503722667694092\n",
      "fold= 3  loss =  1.1421509981155396\n",
      "fold= 4  loss =  1.1422749757766724\n",
      "92.5 90.1 88.4\n",
      "<class 'models.FNN_WS_AUX'> 800 0.013000000000000001 adam\n",
      "fold= 0  loss =  1.1428452730178833\n",
      "fold= 1  loss =  1.207458257675171\n",
      "fold= 2  loss =  1.145609736442566\n",
      "fold= 3  loss =  1.1366630792617798\n",
      "fold= 4  loss =  1.1615418195724487\n",
      "91.3 88.6 86.8\n",
      "<class 'models.FNN_WS_AUX'> 800 0.014 adam\n",
      "fold= 0  loss =  1.1391817331314087\n",
      "fold= 1  loss =  1.14826238155365\n",
      "fold= 2  loss =  1.1574604511260986\n",
      "fold= 3  loss =  1.1535989046096802\n",
      "fold= 4  loss =  1.2002133131027222\n",
      "92.6 89.1 86.9\n",
      "<class 'models.FNN_WS_AUX'> 800 0.015 adam\n",
      "fold= 0  loss =  1.1591863632202148\n",
      "fold= 1  loss =  1.140499234199524\n",
      "fold= 2  loss =  1.1403414011001587\n",
      "fold= 3  loss =  1.1347144842147827\n",
      "fold= 4  loss =  1.140149474143982\n",
      "92.5 90.6 88.7\n",
      "<class 'models.FNN_WS_AUX'> 800 0.016 adam\n",
      "fold= 0  loss =  1.1300288438796997\n",
      "fold= 1  loss =  1.1364654302597046\n",
      "fold= 2  loss =  1.1355948448181152\n",
      "fold= 3  loss =  1.1335787773132324\n",
      "fold= 4  loss =  1.1381875276565552\n",
      "92.4 90.0 88.8\n",
      "<class 'models.FNN_WS_AUX'> 800 0.017 adam\n",
      "fold= 0  loss =  1.1997268199920654\n",
      "fold= 1  loss =  1.2070693969726562\n",
      "fold= 2  loss =  1.1442270278930664\n",
      "fold= 3  loss =  1.134238362312317\n",
      "fold= 4  loss =  1.152355670928955\n",
      "91.2 88.4 86.1\n",
      "<class 'models.FNN_WS_AUX'> 800 0.018000000000000002 adam\n",
      "fold= 0  loss =  1.2302682399749756\n",
      "fold= 1  loss =  1.1349953413009644\n",
      "fold= 2  loss =  1.3529224395751953\n",
      "fold= 3  loss =  1.1331429481506348\n",
      "fold= 4  loss =  1.13551664352417\n",
      "89.6 83.0 82.7\n",
      "<class 'models.FNN_WS_AUX'> 800 0.019 adam\n",
      "fold= 0  loss =  1.227515697479248\n",
      "fold= 1  loss =  1.139860987663269\n",
      "fold= 2  loss =  1.1376830339431763\n",
      "fold= 3  loss =  1.1352723836898804\n",
      "fold= 4  loss =  1.1371687650680542\n",
      "91.7 88.7 87.3\n",
      "<class 'models.FNN_WS_AUX'> 800 0.02 adam\n",
      "fold= 0  loss =  1.2137761116027832\n",
      "fold= 1  loss =  1.1591582298278809\n",
      "fold= 2  loss =  1.3346132040023804\n",
      "fold= 3  loss =  1.1388875246047974\n",
      "fold= 4  loss =  1.2949790954589844\n",
      "85.9 80.9 78.8\n",
      "<class 'models.FNN_WS_AUX'> 800 0.021 adam\n",
      "fold= 0  loss =  1.294404149055481\n",
      "fold= 1  loss =  1.2162460088729858\n",
      "fold= 2  loss =  1.291940450668335\n",
      "fold= 3  loss =  1.140917181968689\n",
      "fold= 4  loss =  1.2603551149368286\n",
      "85.5 79.7 78.7\n",
      "<class 'models.FNN_WS_AUX'> 800 0.022 adam\n",
      "fold= 0  loss =  1.303289771080017\n",
      "fold= 1  loss =  1.1319893598556519\n",
      "fold= 2  loss =  1.2969614267349243\n",
      "fold= 3  loss =  1.235094428062439\n",
      "fold= 4  loss =  1.3898285627365112\n",
      "85.2 76.9 75.7\n",
      "<class 'models.FNN_WS_AUX'> 800 0.023 adam\n",
      "fold= 0  loss =  1.153377652168274\n",
      "fold= 1  loss =  1.3572582006454468\n",
      "fold= 2  loss =  1.3962620496749878\n",
      "fold= 3  loss =  1.3003219366073608\n",
      "fold= 4  loss =  1.2986689805984497\n",
      "84.2 73.9 69.1\n",
      "<class 'models.FNN_WS_AUX'> 800 0.024 adam\n",
      "fold= 0  loss =  1.1738344430923462\n",
      "fold= 1  loss =  1.2982263565063477\n",
      "fold= 2  loss =  1.2575764656066895\n",
      "fold= 3  loss =  1.3514652252197266\n",
      "fold= 4  loss =  1.3650299310684204\n",
      "83.4 73.20000076293945 71.6\n",
      "<class 'models.FNN_AUX'> 800 0.01 adam\n",
      "fold= 0  loss =  1.129332184791565\n",
      "fold= 1  loss =  1.1540354490280151\n",
      "fold= 2  loss =  1.159617304801941\n",
      "fold= 3  loss =  1.1670416593551636\n",
      "fold= 4  loss =  1.135343074798584\n",
      "90.2 84.7 86.5\n",
      "<class 'models.FNN_AUX'> 800 0.011 adam\n",
      "fold= 0  loss =  1.1303762197494507\n",
      "fold= 1  loss =  1.1580791473388672\n",
      "fold= 2  loss =  1.1915680170059204\n",
      "fold= 3  loss =  1.1275080442428589\n",
      "fold= 4  loss =  1.1704659461975098\n",
      "90.2 84.7 86.4\n",
      "<class 'models.FNN_AUX'> 800 0.012 adam\n",
      "fold= 0  loss =  1.1282352209091187\n",
      "fold= 1  loss =  1.153513789176941\n",
      "fold= 2  loss =  1.1924155950546265\n",
      "fold= 3  loss =  1.1589802503585815\n",
      "fold= 4  loss =  1.1976714134216309\n",
      "88.7 80.3 85.9\n",
      "<class 'models.FNN_AUX'> 800 0.013000000000000001 adam\n",
      "fold= 0  loss =  1.1316123008728027\n",
      "fold= 1  loss =  1.1880637407302856\n",
      "fold= 2  loss =  1.2254629135131836\n",
      "fold= 3  loss =  1.1246883869171143\n",
      "fold= 4  loss =  1.1359050273895264\n",
      "87.5 83.7 81.5\n",
      "<class 'models.FNN_AUX'> 800 0.014 adam\n",
      "fold= 0  loss =  1.1248527765274048\n",
      "fold= 1  loss =  1.1299394369125366\n",
      "fold= 2  loss =  1.16046941280365\n",
      "fold= 3  loss =  1.1305757761001587\n",
      "fold= 4  loss =  1.1347222328186035\n",
      "91.3 86.0 87.0\n",
      "<class 'models.FNN_AUX'> 800 0.015 adam\n",
      "fold= 0  loss =  1.1646612882614136\n",
      "fold= 1  loss =  1.1310817003250122\n",
      "fold= 2  loss =  1.193804383277893\n",
      "fold= 3  loss =  1.1567646265029907\n",
      "fold= 4  loss =  1.133592128753662\n",
      "90.1 84.0 86.0\n",
      "<class 'models.FNN_AUX'> 800 0.016 adam\n",
      "fold= 0  loss =  1.2123488187789917\n",
      "fold= 1  loss =  1.148903250694275\n",
      "fold= 2  loss =  1.159661889076233\n",
      "fold= 3  loss =  1.1236882209777832\n",
      "fold= 4  loss =  1.1804074048995972\n",
      "88.9 82.2 85.1\n",
      "<class 'models.FNN_AUX'> 800 0.017 adam\n",
      "fold= 0  loss =  1.1681694984436035\n",
      "fold= 1  loss =  1.1210755109786987\n",
      "fold= 2  loss =  1.1222381591796875\n",
      "fold= 3  loss =  1.1985646486282349\n",
      "fold= 4  loss =  1.1305402517318726\n",
      "90.1 86.4 83.8\n",
      "<class 'models.FNN_AUX'> 800 0.018000000000000002 adam\n",
      "fold= 0  loss =  1.196657657623291\n",
      "fold= 1  loss =  1.266749620437622\n",
      "fold= 2  loss =  1.1843308210372925\n",
      "fold= 3  loss =  1.1903811693191528\n",
      "fold= 4  loss =  1.2527521848678589\n",
      "85.2 81.4 77.3\n",
      "<class 'models.FNN_AUX'> 800 0.019 adam\n",
      "fold= 0  loss =  1.130393385887146\n",
      "fold= 1  loss =  1.1316348314285278\n",
      "fold= 2  loss =  1.1638163328170776\n",
      "fold= 3  loss =  1.217759370803833\n",
      "fold= 4  loss =  1.2736812829971313\n",
      "87.8 83.3 81.7\n",
      "<class 'models.FNN_AUX'> 800 0.02 adam\n",
      "fold= 0  loss =  1.1745314598083496\n",
      "fold= 1  loss =  1.2295135259628296\n",
      "fold= 2  loss =  1.2451900243759155\n",
      "fold= 3  loss =  1.158260703086853\n",
      "fold= 4  loss =  1.126106858253479\n",
      "87.7 81.6 82.1\n",
      "<class 'models.FNN_AUX'> 800 0.021 adam\n",
      "fold= 0  loss =  1.2379342317581177\n",
      "fold= 1  loss =  1.2071915864944458\n",
      "fold= 2  loss =  1.2313828468322754\n",
      "fold= 3  loss =  1.287104606628418\n",
      "fold= 4  loss =  1.1823124885559082\n",
      "86.9 76.9 79.5\n",
      "<class 'models.FNN_AUX'> 800 0.022 adam\n",
      "fold= 0  loss =  1.2533689737319946\n",
      "fold= 1  loss =  1.311038851737976\n",
      "fold= 2  loss =  1.2443665266036987\n",
      "fold= 3  loss =  1.2757301330566406\n",
      "fold= 4  loss =  1.3310924768447876\n",
      "83.0 72.2 73.1\n",
      "<class 'models.FNN_AUX'> 800 0.023 adam\n",
      "fold= 0  loss =  1.2552357912063599\n",
      "fold= 1  loss =  1.2390203475952148\n",
      "fold= 2  loss =  1.224997878074646\n",
      "fold= 3  loss =  1.249941349029541\n",
      "fold= 4  loss =  1.3233660459518433\n",
      "81.8 78.0 71.80000076293945\n",
      "<class 'models.FNN_AUX'> 800 0.024 adam\n",
      "fold= 0  loss =  1.3308454751968384\n",
      "fold= 1  loss =  1.3175983428955078\n",
      "fold= 2  loss =  1.2173867225646973\n",
      "fold= 3  loss =  1.2843295335769653\n",
      "fold= 4  loss =  1.3889960050582886\n",
      "80.2 74.1 64.2\n",
      "<class 'models.CNN'> 800 0.01 adam\n",
      "fold= 0  loss =  0.5866867303848267\n",
      "fold= 1  loss =  0.5544100999832153\n",
      "fold= 2  loss =  0.5510739088058472\n",
      "fold= 3  loss =  0.5763123035430908\n",
      "fold= 4  loss =  0.5596795678138733\n",
      "75.0 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.011 adam\n",
      "fold= 0  loss =  0.5568771958351135\n",
      "fold= 1  loss =  0.5602342486381531\n",
      "fold= 2  loss =  0.5666556358337402\n",
      "fold= 3  loss =  0.5514348745346069\n",
      "fold= 4  loss =  0.5858066082000732\n",
      "74.9 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.012 adam\n",
      "fold= 0  loss =  0.579850971698761\n",
      "fold= 1  loss =  0.5421417355537415\n",
      "fold= 2  loss =  0.5687460899353027\n",
      "fold= 3  loss =  0.568386971950531\n",
      "fold= 4  loss =  0.5708455443382263\n",
      "76.3 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.013000000000000001 adam\n",
      "fold= 0  loss =  0.545033872127533\n",
      "fold= 1  loss =  0.5455797910690308\n",
      "fold= 2  loss =  0.5780689120292664\n",
      "fold= 3  loss =  0.5862154364585876\n",
      "fold= 4  loss =  0.539760410785675\n",
      "75.9 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.014 adam\n",
      "fold= 0  loss =  0.5388790965080261\n",
      "fold= 1  loss =  0.5350282192230225\n",
      "fold= 2  loss =  0.5795504450798035\n",
      "fold= 3  loss =  0.5475680828094482\n",
      "fold= 4  loss =  0.6011128425598145\n",
      "76.1 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.015 adam\n",
      "fold= 0  loss =  0.5538791418075562\n",
      "fold= 1  loss =  0.5383473038673401\n",
      "fold= 2  loss =  0.5503807663917542\n",
      "fold= 3  loss =  0.548324465751648\n",
      "fold= 4  loss =  0.53953617811203\n",
      "75.8 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.016 adam\n",
      "fold= 0  loss =  0.5487074851989746\n",
      "fold= 1  loss =  0.5489753484725952\n",
      "fold= 2  loss =  0.5470450520515442\n",
      "fold= 3  loss =  0.5358147025108337\n",
      "fold= 4  loss =  0.5281453132629395\n",
      "74.8 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.017 adam\n",
      "fold= 0  loss =  0.5269769430160522\n",
      "fold= 1  loss =  0.5230153799057007\n",
      "fold= 2  loss =  0.6862261891365051\n",
      "fold= 3  loss =  0.5451734662055969\n",
      "fold= 4  loss =  0.566346287727356\n",
      "71.4 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.018000000000000002 adam\n",
      "fold= 0  loss =  0.5402494668960571\n",
      "fold= 1  loss =  0.5866462588310242\n",
      "fold= 2  loss =  0.515296220779419\n",
      "fold= 3  loss =  0.5408040285110474\n",
      "fold= 4  loss =  0.5205686092376709\n",
      "77.2 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.019 adam\n",
      "fold= 0  loss =  0.5212439894676208\n",
      "fold= 1  loss =  0.51235032081604\n",
      "fold= 2  loss =  0.5887274742126465\n",
      "fold= 3  loss =  0.5271756649017334\n",
      "fold= 4  loss =  0.5595735311508179\n",
      "74.2 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.02 adam\n",
      "fold= 0  loss =  0.6892733573913574\n",
      "fold= 1  loss =  0.5248048305511475\n",
      "fold= 2  loss =  0.5375671982765198\n",
      "fold= 3  loss =  0.5755051970481873\n",
      "fold= 4  loss =  0.5458604693412781\n",
      "71.1 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.021 adam\n",
      "fold= 0  loss =  0.5109450817108154\n",
      "fold= 1  loss =  0.5205904245376587\n",
      "fold= 2  loss =  0.686299204826355\n",
      "fold= 3  loss =  0.5182528495788574\n",
      "fold= 4  loss =  0.6850171685218811\n",
      "68.0 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.022 adam\n",
      "fold= 0  loss =  0.5389466285705566\n",
      "fold= 1  loss =  0.5525882244110107\n",
      "fold= 2  loss =  0.591558039188385\n",
      "fold= 3  loss =  0.6879702806472778\n",
      "fold= 4  loss =  0.5113989114761353\n",
      "71.6 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.023 adam\n",
      "fold= 0  loss =  0.553209662437439\n",
      "fold= 1  loss =  0.6905767321586609\n",
      "fold= 2  loss =  0.6862351298332214\n",
      "fold= 3  loss =  0.550360918045044\n",
      "fold= 4  loss =  0.5365616083145142\n",
      "68.3 0.0 0.0\n",
      "<class 'models.CNN'> 800 0.024 adam\n",
      "fold= 0  loss =  0.5163945555686951\n",
      "fold= 1  loss =  0.554934561252594\n",
      "fold= 2  loss =  0.5449321269989014\n",
      "fold= 3  loss =  0.6879228353500366\n",
      "fold= 4  loss =  0.6850106120109558\n",
      "66.0 0.0 0.0\n",
      "<class 'models.CNN_WS_AUX'> 800 0.01 adam\n",
      "fold= 0  loss =  1.1906217336654663\n",
      "fold= 1  loss =  1.3434243202209473\n",
      "fold= 2  loss =  1.2533599138259888\n",
      "fold= 3  loss =  1.2102155685424805\n",
      "fold= 4  loss =  1.1928220987319946\n",
      "86.8 81.3 79.4\n",
      "<class 'models.CNN_WS_AUX'> 800 0.011 adam\n",
      "fold= 0  loss =  1.1334627866744995\n",
      "fold= 1  loss =  1.2384098768234253\n",
      "fold= 2  loss =  1.1721148490905762\n",
      "fold= 3  loss =  1.15019953250885\n",
      "fold= 4  loss =  1.1419633626937866\n",
      "92.1 89.6 89.1\n",
      "<class 'models.CNN_WS_AUX'> 800 0.012 adam\n",
      "fold= 0  loss =  1.1500908136367798\n",
      "fold= 1  loss =  1.1483010053634644\n",
      "fold= 2  loss =  1.2712243795394897\n",
      "fold= 3  loss =  1.2211543321609497\n",
      "fold= 4  loss =  1.2230299711227417\n",
      "88.6 85.3 83.3\n",
      "<class 'models.CNN_WS_AUX'> 800 0.013000000000000001 adam\n",
      "fold= 0  loss =  1.1421382427215576\n",
      "fold= 1  loss =  1.2160208225250244\n",
      "fold= 2  loss =  1.1585941314697266\n",
      "fold= 3  loss =  1.1306267976760864\n",
      "fold= 4  loss =  1.1415644884109497\n",
      "92.9 91.1 88.7\n",
      "<class 'models.CNN_WS_AUX'> 800 0.014 adam\n",
      "fold= 0  loss =  1.1724494695663452\n",
      "fold= 1  loss =  1.2793055772781372\n",
      "fold= 2  loss =  1.155903935432434\n",
      "fold= 3  loss =  1.1584519147872925\n",
      "fold= 4  loss =  1.1501597166061401\n",
      "91.4 87.6 86.5\n",
      "<class 'models.CNN_WS_AUX'> 800 0.015 adam\n",
      "fold= 0  loss =  1.1274195909500122\n",
      "fold= 1  loss =  1.1621443033218384\n",
      "fold= 2  loss =  1.1891226768493652\n",
      "fold= 3  loss =  1.2333297729492188\n",
      "fold= 4  loss =  1.1328229904174805\n",
      "93.3 89.2 87.2\n",
      "<class 'models.CNN_WS_AUX'> 800 0.016 adam\n",
      "fold= 0  loss =  1.220276951789856\n",
      "fold= 1  loss =  1.1339393854141235\n",
      "fold= 2  loss =  1.1368411779403687\n",
      "fold= 3  loss =  1.150215983390808\n",
      "fold= 4  loss =  1.1381322145462036\n",
      "93.0 89.3 88.7\n",
      "<class 'models.CNN_WS_AUX'> 800 0.017 adam\n",
      "fold= 0  loss =  1.1337965726852417\n",
      "fold= 1  loss =  1.1585274934768677\n",
      "fold= 2  loss =  1.2062374353408813\n",
      "fold= 3  loss =  1.158926010131836\n",
      "fold= 4  loss =  1.1457122564315796\n",
      "92.2 89.0 88.3\n",
      "<class 'models.CNN_WS_AUX'> 800 0.018000000000000002 adam\n",
      "fold= 0  loss =  1.236477255821228\n",
      "fold= 1  loss =  1.1316536664962769\n",
      "fold= 2  loss =  1.1437252759933472\n",
      "fold= 3  loss =  1.1363822221755981\n",
      "fold= 4  loss =  1.1366573572158813\n",
      "93.1 90.6 88.9\n",
      "<class 'models.CNN_WS_AUX'> 800 0.019 adam\n",
      "fold= 0  loss =  1.1404423713684082\n",
      "fold= 1  loss =  1.149274230003357\n",
      "fold= 2  loss =  1.1314784288406372\n",
      "fold= 3  loss =  1.2158797979354858\n",
      "fold= 4  loss =  1.1497656106948853\n",
      "92.4 89.8 87.6\n",
      "<class 'models.CNN_WS_AUX'> 800 0.02 adam\n",
      "fold= 0  loss =  1.1395535469055176\n",
      "fold= 1  loss =  1.1430045366287231\n",
      "fold= 2  loss =  1.1510816812515259\n",
      "fold= 3  loss =  1.1932765245437622\n",
      "fold= 4  loss =  1.141058325767517\n",
      "93.5 90.2 90.9\n",
      "<class 'models.CNN_WS_AUX'> 800 0.021 adam\n",
      "fold= 0  loss =  1.1516896486282349\n",
      "fold= 1  loss =  1.1406177282333374\n",
      "fold= 2  loss =  1.147800087928772\n",
      "fold= 3  loss =  1.1404472589492798\n",
      "fold= 4  loss =  1.1297675371170044\n",
      "94.2 92.5 90.1\n",
      "<class 'models.CNN_WS_AUX'> 800 0.022 adam\n",
      "fold= 0  loss =  1.2986403703689575\n",
      "fold= 1  loss =  1.135971188545227\n",
      "fold= 2  loss =  1.1395376920700073\n",
      "fold= 3  loss =  1.1297608613967896\n",
      "fold= 4  loss =  1.1302399635314941\n",
      "93.0 89.1 88.1\n",
      "<class 'models.CNN_WS_AUX'> 800 0.023 adam\n",
      "fold= 0  loss =  1.2624648809432983\n",
      "fold= 1  loss =  1.1369285583496094\n",
      "fold= 2  loss =  1.1347359418869019\n",
      "fold= 3  loss =  1.2480484247207642\n",
      "fold= 4  loss =  1.1656781435012817\n",
      "91.5 88.2 86.4\n",
      "<class 'models.CNN_WS_AUX'> 800 0.024 adam\n",
      "fold= 0  loss =  1.1410813331604004\n",
      "fold= 1  loss =  1.240451455116272\n",
      "fold= 2  loss =  1.2570286989212036\n",
      "fold= 3  loss =  1.147684097290039\n",
      "fold= 4  loss =  1.6741204261779785\n",
      "82.8 73.1 74.10000038146973\n",
      "<class 'models.CNN_WS'> 800 0.01 adam\n",
      "fold= 0  loss =  0.6118124723434448\n",
      "fold= 1  loss =  0.5581858158111572\n",
      "fold= 2  loss =  0.583972692489624\n",
      "fold= 3  loss =  0.5724579691886902\n",
      "fold= 4  loss =  0.5788373947143555\n",
      "74.6 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.011 adam\n",
      "fold= 0  loss =  0.6052682995796204\n",
      "fold= 1  loss =  0.5551788806915283\n",
      "fold= 2  loss =  0.5584011077880859\n",
      "fold= 3  loss =  0.5718117356300354\n",
      "fold= 4  loss =  0.5609725117683411\n",
      "75.4 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.012 adam\n",
      "fold= 0  loss =  0.5476913452148438\n",
      "fold= 1  loss =  0.5572574138641357\n",
      "fold= 2  loss =  0.5619425773620605\n",
      "fold= 3  loss =  0.5614402890205383\n",
      "fold= 4  loss =  0.5428666472434998\n",
      "74.4 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.013000000000000001 adam\n",
      "fold= 0  loss =  0.6892664432525635\n",
      "fold= 1  loss =  0.5413838028907776\n",
      "fold= 2  loss =  0.5627917647361755\n",
      "fold= 3  loss =  0.5612146854400635\n",
      "fold= 4  loss =  0.549997091293335\n",
      "72.6 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.014 adam\n",
      "fold= 0  loss =  0.5710996985435486\n",
      "fold= 1  loss =  0.6905566453933716\n",
      "fold= 2  loss =  0.5396021008491516\n",
      "fold= 3  loss =  0.554817795753479\n",
      "fold= 4  loss =  0.5635722875595093\n",
      "72.9 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.015 adam\n",
      "fold= 0  loss =  0.5290984511375427\n",
      "fold= 1  loss =  0.5247333645820618\n",
      "fold= 2  loss =  0.5431203246116638\n",
      "fold= 3  loss =  0.553128182888031\n",
      "fold= 4  loss =  0.5554149150848389\n",
      "75.5 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.016 adam\n",
      "fold= 0  loss =  0.5278995633125305\n",
      "fold= 1  loss =  0.5420898795127869\n",
      "fold= 2  loss =  0.6862406134605408\n",
      "fold= 3  loss =  0.5503681302070618\n",
      "fold= 4  loss =  0.5316735506057739\n",
      "71.2 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.017 adam\n",
      "fold= 0  loss =  0.5827073454856873\n",
      "fold= 1  loss =  0.5316417813301086\n",
      "fold= 2  loss =  0.5335609316825867\n",
      "fold= 3  loss =  0.5457304120063782\n",
      "fold= 4  loss =  0.5358250141143799\n",
      "75.7 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.018000000000000002 adam\n",
      "fold= 0  loss =  0.6892217397689819\n",
      "fold= 1  loss =  0.5355090498924255\n",
      "fold= 2  loss =  0.5525403022766113\n",
      "fold= 3  loss =  0.5585777759552002\n",
      "fold= 4  loss =  0.5333403944969177\n",
      "72.0 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.019 adam\n",
      "fold= 0  loss =  0.5192288160324097\n",
      "fold= 1  loss =  0.5319228172302246\n",
      "fold= 2  loss =  0.6862357258796692\n",
      "fold= 3  loss =  0.6878909468650818\n",
      "fold= 4  loss =  0.5252922177314758\n",
      "66.7 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.02 adam\n",
      "fold= 0  loss =  0.689098060131073\n",
      "fold= 1  loss =  0.5171873569488525\n",
      "fold= 2  loss =  0.5186928510665894\n",
      "fold= 3  loss =  0.528049647808075\n",
      "fold= 4  loss =  0.6850183010101318\n",
      "66.7 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.021 adam\n",
      "fold= 0  loss =  0.5392369627952576\n",
      "fold= 1  loss =  0.5414233803749084\n",
      "fold= 2  loss =  0.5303006172180176\n",
      "fold= 3  loss =  0.5106855630874634\n",
      "fold= 4  loss =  0.6850332617759705\n",
      "71.0 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.022 adam\n",
      "fold= 0  loss =  0.5229891538619995\n",
      "fold= 1  loss =  0.5093885660171509\n",
      "fold= 2  loss =  0.5143309831619263\n",
      "fold= 3  loss =  0.5377985835075378\n",
      "fold= 4  loss =  0.6850066184997559\n",
      "71.5 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.023 adam\n",
      "fold= 0  loss =  0.6892381906509399\n",
      "fold= 1  loss =  0.5071950554847717\n",
      "fold= 2  loss =  0.5503402948379517\n",
      "fold= 3  loss =  0.5321773290634155\n",
      "fold= 4  loss =  0.6850119233131409\n",
      "67.3 0.0 0.0\n",
      "<class 'models.CNN_WS'> 800 0.024 adam\n",
      "fold= 0  loss =  0.5063558220863342\n",
      "fold= 1  loss =  0.5340673327445984\n",
      "fold= 2  loss =  0.5046699047088623\n",
      "fold= 3  loss =  0.5174044966697693\n",
      "fold= 4  loss =  0.5730788111686707\n",
      "77.7 0.0 0.0\n",
      "<class 'models.CNN_AUX'> 800 0.01 adam\n",
      "fold= 0  loss =  1.210218071937561\n",
      "fold= 1  loss =  1.273598074913025\n",
      "fold= 2  loss =  1.287483811378479\n",
      "fold= 3  loss =  1.2206424474716187\n",
      "fold= 4  loss =  1.201316475868225\n",
      "85.6 77.3 79.0\n",
      "<class 'models.CNN_AUX'> 800 0.011 adam\n",
      "fold= 0  loss =  1.133078694343567\n",
      "fold= 1  loss =  1.2719937562942505\n",
      "fold= 2  loss =  1.2028981447219849\n",
      "fold= 3  loss =  1.2317752838134766\n",
      "fold= 4  loss =  1.2103806734085083\n",
      "87.0 84.5 78.0\n",
      "<class 'models.CNN_AUX'> 800 0.012 adam\n",
      "fold= 0  loss =  1.2770400047302246\n",
      "fold= 1  loss =  1.1996947526931763\n",
      "fold= 2  loss =  1.2846897840499878\n",
      "fold= 3  loss =  1.1774402856826782\n",
      "fold= 4  loss =  1.1870574951171875\n",
      "85.1 79.8 77.1\n",
      "<class 'models.CNN_AUX'> 800 0.013000000000000001 adam\n",
      "fold= 0  loss =  1.2292636632919312\n",
      "fold= 1  loss =  1.2463785409927368\n",
      "fold= 2  loss =  1.2201571464538574\n",
      "fold= 3  loss =  1.2116633653640747\n",
      "fold= 4  loss =  1.133054256439209\n",
      "86.3 82.2 78.7\n",
      "<class 'models.CNN_AUX'> 800 0.014 adam\n",
      "fold= 0  loss =  1.1596275568008423\n",
      "fold= 1  loss =  1.2554924488067627\n",
      "fold= 2  loss =  1.1959688663482666\n",
      "fold= 3  loss =  1.2455189228057861\n",
      "fold= 4  loss =  1.1379268169403076\n",
      "87.6 80.3 82.9\n",
      "<class 'models.CNN_AUX'> 800 0.015 adam\n",
      "fold= 0  loss =  1.1328784227371216\n",
      "fold= 1  loss =  1.2011879682540894\n",
      "fold= 2  loss =  1.2536959648132324\n",
      "fold= 3  loss =  1.1444542407989502\n",
      "fold= 4  loss =  1.130623698234558\n",
      "88.0 83.8 84.5\n",
      "<class 'models.CNN_AUX'> 800 0.016 adam\n",
      "fold= 0  loss =  1.1884714365005493\n",
      "fold= 1  loss =  1.2084527015686035\n",
      "fold= 2  loss =  1.2104110717773438\n",
      "fold= 3  loss =  1.1365864276885986\n",
      "fold= 4  loss =  1.135718822479248\n",
      "89.5 84.0 84.8\n",
      "<class 'models.CNN_AUX'> 800 0.017 adam\n",
      "fold= 0  loss =  1.1264883279800415\n",
      "fold= 1  loss =  1.1726036071777344\n",
      "fold= 2  loss =  1.1447361707687378\n",
      "fold= 3  loss =  1.1979081630706787\n",
      "fold= 4  loss =  1.142385721206665\n",
      "92.8 86.7 88.4\n",
      "<class 'models.CNN_AUX'> 800 0.018000000000000002 adam\n",
      "fold= 0  loss =  1.1221215724945068\n",
      "fold= 1  loss =  1.1905020475387573\n",
      "fold= 2  loss =  1.1290010213851929\n",
      "fold= 3  loss =  1.156261920928955\n",
      "fold= 4  loss =  1.1683539152145386\n",
      "91.4 86.1 87.5\n",
      "<class 'models.CNN_AUX'> 800 0.019 adam\n",
      "fold= 0  loss =  1.1624900102615356\n",
      "fold= 1  loss =  1.1702944040298462\n",
      "fold= 2  loss =  1.1812492609024048\n",
      "fold= 3  loss =  1.167671799659729\n",
      "fold= 4  loss =  1.1235158443450928\n",
      "90.5 86.8 86.4\n",
      "<class 'models.CNN_AUX'> 800 0.02 adam\n",
      "fold= 0  loss =  1.1455227136611938\n",
      "fold= 1  loss =  1.128961443901062\n",
      "fold= 2  loss =  1.3229713439941406\n",
      "fold= 3  loss =  1.180243968963623\n",
      "fold= 4  loss =  1.1386853456497192\n",
      "89.9 82.1 86.5\n",
      "<class 'models.CNN_AUX'> 800 0.021 adam\n",
      "fold= 0  loss =  1.2152572870254517\n",
      "fold= 1  loss =  1.3746418952941895\n",
      "fold= 2  loss =  1.2185442447662354\n",
      "fold= 3  loss =  1.135546326637268\n",
      "fold= 4  loss =  1.2046056985855103\n",
      "86.4 84.8 76.2\n",
      "<class 'models.CNN_AUX'> 800 0.022 adam\n",
      "fold= 0  loss =  1.2561382055282593\n",
      "fold= 1  loss =  1.1738585233688354\n",
      "fold= 2  loss =  1.2080920934677124\n",
      "fold= 3  loss =  1.1697419881820679\n",
      "fold= 4  loss =  1.1917610168457031\n",
      "88.1 86.1 78.1\n",
      "<class 'models.CNN_AUX'> 800 0.023 adam\n",
      "fold= 0  loss =  1.2675583362579346\n",
      "fold= 1  loss =  1.2321025133132935\n",
      "fold= 2  loss =  1.2126363515853882\n",
      "fold= 3  loss =  1.236398696899414\n",
      "fold= 4  loss =  1.146919846534729\n",
      "87.1 83.4 78.2\n",
      "<class 'models.CNN_AUX'> 800 0.024 adam\n",
      "fold= 0  loss =  1.153403878211975\n",
      "fold= 1  loss =  1.2379026412963867\n",
      "fold= 2  loss =  1.2245006561279297\n",
      "fold= 3  loss =  1.1682004928588867\n",
      "fold= 4  loss =  1.3241877555847168\n",
      "88.5 80.7 81.5\n"
     ]
    }
   ],
   "source": [
    "#dont run this unless you wanna tune the hyperparemeters for yourself.\n",
    "models = [FNN, FNN_WS, FNN_WS_AUX, FNN_AUX, CNN, CNN_WS_AUX, CNN_WS, CNN_AUX]\n",
    "batch_sizes = [800]\n",
    "lrs = [0.001 * x for x in range(10, 25)]\n",
    "opts = ['adam']\n",
    "\n",
    "for m in models:\n",
    "    for b in batch_sizes:\n",
    "        for lr in lrs:\n",
    "            for opt in opts:\n",
    "                print(m, b, lr, opt)\n",
    "                acc_t, acc_d1, acc_d2 = cross_val_score(train_input1, train_input2, train_classes1, train_classes2,  train_target, m, opt,lr,b, k_folds=5)\n",
    "                print(acc_t, acc_d1, acc_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FNN = model_selector(FNN, 'adam', 0.02, 1000)\n",
    "model_FNN_WS = model_selector(FNN_WS, 'adam', 0.017, 1000)\n",
    "model_FNN_WS_AUX = model_selector(FNN_WS_AUX, 'adam', 0.014, 1000)\n",
    "model_FNN_AUX = model_selector(FNN_AUX, 'adam', 0.014, 1000)\n",
    "\n",
    "model_CNN = model_selector(CNN, 'adam', 0.012, 1000)\n",
    "model_CNN_WS_AUX = model_selector(CNN_WS_AUX, 'adam', 0.018, 1000)\n",
    "model_CNN_WS = model_selector(CNN_WS, 'adam', 0.017, 1000)\n",
    "model_CNN_AUX = model_selector(CNN_AUX, 'adam', 0.017, 1000)\n",
    "\n",
    "models = [model_FNN, model_FNN_WS, model_FNN_WS_AUX, model_FNN_AUX, model_CNN, model_CNN_WS_AUX, model_CNN_WS, model_CNN_AUX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.9000015258789\n",
      "73.9000015258789\n",
      "94.9000015258789\n",
      "93.5\n",
      "74.0\n",
      "96.9000015258789\n",
      "73.69999694824219\n",
      "95.30000305175781\n"
     ]
    }
   ],
   "source": [
    "# plots\n",
    "histories = []\n",
    "load()\n",
    "for m in models:\n",
    "    history = train_model(m, train_input1, train_input2, train_classes1, train_classes2, train_target)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  [69.85999984741211]\n",
      "std  [0.4630339572414887]\n",
      "mean  [69.85999984741211, 72.67999801635742]\n",
      "std  [0.4630339572414887, 1.0077676255808858]\n",
      "mean  [69.85999984741211, 72.67999801635742, 94.85000305175781]\n",
      "std  [0.4630339572414887, 1.0077676255808858, 0.16881888785301316]\n",
      "mean  [69.85999984741211, 72.67999801635742, 94.85000305175781, 93.84999923706054]\n",
      "std  [0.4630339572414887, 1.0077676255808858, 0.16881888785301316, 0.1688195657588387]\n",
      "mean  [69.85999984741211, 72.67999801635742, 94.85000305175781, 93.84999923706054, 74.70999908447266]\n",
      "std  [0.4630339572414887, 1.0077676255808858, 0.16881888785301316, 0.1688195657588387, 0.4700017076891914]\n",
      "mean  [69.85999984741211, 72.67999801635742, 94.85000305175781, 93.84999923706054, 74.70999908447266, 96.91000061035156]\n",
      "std  [0.4630339572414887, 1.0077676255808858, 0.16881888785301316, 0.1688195657588387, 0.4700017076891914, 0.09434007012158958]\n",
      "mean  [69.85999984741211, 72.67999801635742, 94.85000305175781, 93.84999923706054, 74.70999908447266, 96.91000061035156, 72.8599967956543]\n",
      "std  [0.4630339572414887, 1.0077676255808858, 0.16881888785301316, 0.1688195657588387, 0.4700017076891914, 0.09434007012158958, 0.3773601995677966]\n",
      "mean  [69.85999984741211, 72.67999801635742, 94.85000305175781, 93.84999923706054, 74.70999908447266, 96.91000061035156, 72.8599967956543, 95.60999984741211]\n",
      "std  [0.4630339572414887, 1.0077676255808858, 0.16881888785301316, 0.1688195657588387, 0.4700017076891914, 0.09434007012158958, 0.3773601995677966, 0.09434063623123705]\n"
     ]
    }
   ],
   "source": [
    "# performance\n",
    "\n",
    "modelMean = []\n",
    "modelStd = []\n",
    "for m in models:\n",
    "    accs = []\n",
    "    for i in range(10):\n",
    "        load()\n",
    "        train_model(m, train_input1, train_input2, train_classes1, train_classes2, train_target)\n",
    "        acc = compute_nb_errors(m['model'], test_input1, test_input2, test_classes1, test_classes2, test_target)\n",
    "        accs.append(acc[0])\n",
    "    modelMean.append(numpy.mean(accs))\n",
    "    modelStd.append(numpy.std(accs))\n",
    "\n",
    "print(\"means \", modelMean)\n",
    "print(\"stds \", modelStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized performance (to not load 10*nb models but only 10 times the datas)\n",
    "\n",
    "dixAccs = []\n",
    "for i in range(10):\n",
    "    load()\n",
    "    accs = []\n",
    "    for m in models:\n",
    "        train_model(m, train_input1, train_input2, train_classes1, train_classes2, train_target)\n",
    "        acc = compute_nb_errors(m['model'], test_input1, test_input2, test_classes1, test_classes2, test_target)\n",
    "        accs.append(acc[0])\n",
    "    dixAccs.append(accs)\n",
    "  \n",
    "modelM = []\n",
    "modelS = []\n",
    "for m in models:       \n",
    "    modelM.append(numpy.mean(accs, axis = m))\n",
    "    modelS.append(numpy.std(accs, axis = m))\n",
    "    \n",
    "print(\"means \", modelM)\n",
    "print(\"stds \", modelS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(histories, x_label, y_label, line_labels):\n",
    "    losses = [hist['loss_history'] for hist in histories]\n",
    "    for l,n in zip(losses,line_labels):\n",
    "        plt.plot(l, label = n)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_names = [x['model'].__class__.__name__ for x in models]\n",
    "plotLoss(histories[:2] + [histories[4]] + [histories[6]], '#of epochs', 'loss', curve_names[:2] + [curve_names[4]] + [curve_names[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss([histories[7]] + [histories[5]] + histories[2:4], '#of epochs', 'loss',  [curve_names[7]] + [curve_names[5]] + curve_names[2:4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
