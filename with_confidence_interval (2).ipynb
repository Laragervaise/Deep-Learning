{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import dlc_practical_prologue as prologue\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from models import FNN, FNN_WS, FNN_WS_AUX, FNN_AUX, CNN, CNN_WS_AUX, CNN_WS, CNN_AUX\n",
    "import statistics\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "\n",
    "    # Load the data\n",
    "    size = 1000\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(size)\n",
    "\n",
    "    #normalization\n",
    "    #check https://stats.stackexchange.com/questions/174823/\n",
    "    mu, std = train_input.mean(), train_input.std()\n",
    "    train_input, test_input = train_input.sub(mu).div(std), test_input.sub(mu).div(std)\n",
    "\n",
    "    #split the images\n",
    "    train_input1, train_input2 = train_input[:, 0, :, :], train_input[:, 1, :, :] \n",
    "    test_input1, test_input2 = test_input[:, 0, :, :], test_input[:, 1, :, :] \n",
    "\n",
    "    #split the number pairs\n",
    "    train_classes1, train_classes2 = train_classes[:, 0], train_classes[:, 1]\n",
    "    test_classes1, test_classes2 = test_classes[:, 0], test_classes[:, 1]\n",
    "    \n",
    "    list = [train_input1, train_input2, test_input1, test_input2, train_classes1, train_classes2, test_classes1, test_classes2, train_target, test_target]\n",
    "    \n",
    "    return list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " [train_input1, train_input2, test_input1, test_input2, train_classes1, train_classes2, test_classes1, test_classes2, train_target, test_target] = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param model: a dict encapsulating the model and its properties\n",
    ":param inps1: lhs of image pairs\n",
    ":param inps2: rhs of image pairs\n",
    ":param digits1: classes of inps1 \n",
    ":param digits2: classes of inps2\n",
    ":param targets: final boolean value indicating whether lhs <= rhs\n",
    ":return: a dict encapsulating the model history\n",
    "\"\"\"\n",
    "def train_model(model, inps1, inps2, digits1, digits2, targets):\n",
    "    \n",
    "    epochs = model['nb_epochs']\n",
    "    batch_size = model['batch_size']\n",
    "    criterion = model['criterion']\n",
    "    optimizer = model['optimizer']\n",
    "    mdl = model['model']\n",
    "      \n",
    "    #  a dict to return whatever value we wanna return\n",
    "    #  e.g. loss at each epoch (useful for plotting)\n",
    "    model_history = dict()\n",
    "    \n",
    "    \n",
    "    loss_history = [] #a list to keep track of the losses at each epoch\n",
    "    for e in range(epochs):\n",
    "        train_indices = random.sample(range(inps1.size(0)), batch_size)  # pick a minibatch   \n",
    "        d1, d2, pred = mdl(inps1[train_indices], inps2[train_indices])   # run through the network\n",
    "        pred_loss =  criterion(pred.view(-1, 2), targets[train_indices]) # loss due to boolean value\n",
    "            \n",
    "        #this is where auxillary loss happens depending on the model.\n",
    "        #if a model returns the digit information, it is taken into account in the backprop.\n",
    "        #if there is no digit info only loss we have is the one due to boolean above\n",
    "        if d1 is not None:\n",
    "            pred_loss += criterion(d1.view(-1, 10), digits1[train_indices])\n",
    "            pred_loss += criterion(d2.view(-1, 10), digits2[train_indices])\n",
    "            pred_loss /= 3\n",
    "            \n",
    "        loss = pred_loss.item() #magnitude of the loss\n",
    "        mdl.zero_grad()         #reset the gradients for this epoch\n",
    "        pred_loss.backward()    #calculate the gradients\n",
    "        optimizer.step()        #update the weights\n",
    "            \n",
    "\n",
    "        loss_history.append(loss) #record the loss \n",
    "        \n",
    "    model_history['loss_history'] = loss_history\n",
    "    return model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param model: a dict encapsulating the model and its properties\n",
    ":param inps1: lhs of image pairs\n",
    ":param inps2: rhs of image pairs\n",
    ":param digits1: classes of inps1 \n",
    ":param digits2: classes of inps2\n",
    ":param targets: final boolean value indicating whether lhs <= rhs\n",
    ":return: a triplet indicating the accuracies ordered as (boolean,lhs,rhs)\n",
    "\"\"\"\n",
    "def compute_nb_errors(model, inps1, inps2, digits1, digits2, targets):\n",
    "    n_samples = inps1.shape[0]\n",
    "    \n",
    "    d1,d2,pred = model(inps1, inps2)           # predict the digits + boolean\n",
    "    _, indices = torch.max(pred.view(-1,2), 1) # torch.max returns the max value from the distribution and its corresponding index\n",
    "    acc_target = (sum(indices == targets) / float(n_samples) * 100).item()  #calculate accuracy\n",
    "\n",
    "    acc_d1, acc_d2 = 0, 0\n",
    "    if d1 is not None: #the model returns digits if it makes use of aux loss. in this case we can report the accuracy of predicting the digits.\n",
    "        _, indices1 = torch.max(d1.view(-1,10), 1)\n",
    "        _, indices2 = torch.max(d2.view(-1,10), 1)\n",
    "        acc_d1 += (sum(indices1 == digits1) / float(n_samples) * 100).item()\n",
    "        acc_d2 += (sum(indices2 == digits2) / float(n_samples) * 100).item()\n",
    "    \n",
    "    \n",
    "    return (acc_target, acc_d1, acc_d2)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param model_constructor: constructor for the model\n",
    ":param optimizer_name: 'sgd' or 'adam'\n",
    ":param lr: learning rate\n",
    ":param batch_size: batch_size.\n",
    ":return: an encapsulated model ready for the training\n",
    "\"\"\"\n",
    "def model_selector(model_constructor, optimizer_name, lr, batch_size):\n",
    "    model = dict()\n",
    "    model['model'] = model_constructor()\n",
    "    model['criterion'] = nn.CrossEntropyLoss()\n",
    "    model['nb_epochs'] = 25\n",
    "    model['batch_size'] = batch_size\n",
    "    if(optimizer_name == 'sgd'):\n",
    "        model['optimizer'] = torch.optim.SGD(model['model'].parameters(), lr=lr, momentum=0.9)\n",
    "    elif optimizer_name == 'adam':\n",
    "        model['optimizer'] =  torch.optim.Adam(model['model'].parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param inps1: lhs of image pairs\n",
    ":param inps2: rhs of image pairs\n",
    ":param digits1: classes of inps1 \n",
    ":param digits2: classes of inps2\n",
    ":param targets: final boolean value indicating whether lhs <= rhs\n",
    ":return: a triplet indicating the accuracies ordered as (boolean,lhs,rhs)\n",
    "\"\"\"\n",
    "def cross_val_score(inps1, inps2, digits1, digits2, targets, model_constructor, optimizer_name, lr, batch_size, k_folds=5):\n",
    "    len_train = inps1.shape[0]\n",
    "    indices = [i for i in range(len_train)]\n",
    "    random.seed(8)\n",
    "    random.shuffle(indices)\n",
    "    acc_target, acc_d1, acc_d2  = 0,0,0\n",
    "    for k in range(k_folds):\n",
    "        model = model_selector(model_constructor, optimizer_name, lr, batch_size)  # init the same model\n",
    "        val_indices = indices[k*len_train//k_folds:(k+1)*len_train//k_folds] # 1 validation fold\n",
    "        train_indices = list(set(indices) - set(val_indices))                # k-1 training fold\n",
    "        \n",
    "        #train the model with k-1 training fold\n",
    "        history = train_model(model, inps1[train_indices], inps2[train_indices], digits1[train_indices], digits2[train_indices], targets[train_indices])\n",
    "        \n",
    "        #compute the accuracy on 1 validation fold\n",
    "        accs = compute_nb_errors(model['model'], inps1[val_indices], inps2[val_indices], digits1[val_indices], digits2[val_indices], targets[val_indices])\n",
    "        \n",
    "        acc_target += accs[0]\n",
    "        acc_d1 += accs[1]\n",
    "        acc_d2 += accs[2]\n",
    "        print('fold=', k, ' loss = ', history['loss_history'][-1])\n",
    "    return (acc_target / k_folds, acc_d1 /k_folds, acc_d2 /k_folds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'models.FNN'> 800 0.01 adam\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_input1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4895e9826f10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0macc_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_d1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_d2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_classes1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_classes2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_d1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_d2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_input1' is not defined"
     ]
    }
   ],
   "source": [
    "#dont run this unless you wanna tune the hyperparemeters for yourself.\n",
    "models = [FNN, FNN_WS, FNN_WS_AUX, FNN_AUX, CNN, CNN_WS_AUX, CNN_WS, CNN_AUX]\n",
    "batch_sizes = [800]\n",
    "lrs = [0.001 * x for x in range(10, 25)]\n",
    "opts = ['adam']\n",
    "\n",
    "for m in models:\n",
    "    for b in batch_sizes:\n",
    "        for lr in lrs:\n",
    "            for opt in opts:\n",
    "                print(m, b, lr, opt)\n",
    "                acc_t, acc_d1, acc_d2 = cross_val_score(train_input1, train_input2, train_classes1, train_classes2,  train_target, m, opt,lr,b, k_folds=5)\n",
    "                print(acc_t, acc_d1, acc_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 500\n",
    "\n",
    "model_FNN = model_selector(FNN, 'adam', 0.02, batchSize)\n",
    "model_FNN_WS = model_selector(FNN_WS, 'adam', 0.017, batchSize)\n",
    "model_FNN_WS_AUX = model_selector(FNN_WS_AUX, 'adam', 0.014, batchSize)\n",
    "model_FNN_AUX = model_selector(FNN_AUX, 'adam', 0.014, batchSize)\n",
    "\n",
    "model_CNN = model_selector(CNN, 'adam', 0.012, batchSize)\n",
    "model_CNN_WS_AUX = model_selector(CNN_WS_AUX, 'adam', 0.018, batchSize)\n",
    "model_CNN_WS = model_selector(CNN_WS, 'adam', 0.017, batchSize)\n",
    "model_CNN_AUX = model_selector(CNN_AUX, 'adam', 0.017, batchSize)\n",
    "\n",
    "models = [model_FNN, model_FNN_WS, model_FNN_WS_AUX, model_FNN_AUX, model_CNN, model_CNN_WS_AUX, model_CNN_WS, model_CNN_AUX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "histories = []\n",
    "for m in models:\n",
    "    history = train_model(m, train_input1, train_input2, train_classes1, train_classes2, train_target)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc means  [71.85, 54.900000762939456, 96.29999923706055, 93.55, 67.53000030517578, 97.88999786376954, 55.28999977111816, 96.55000076293945]\n",
      "acc stds  [2.4352601763412656, 1.6043681646199621, 0.7523276664698046, 1.5337878562549863, 4.699160396822751, 0.5430470323540957, 1.5076143869824012, 0.710280785717198]\n",
      "time means  [0.34356673789989145, 0.23964570589996584, 0.8034305544997551, 1.0472290086994689, 1.8399965780005005, 4.168143386799966, 1.6342655071999617, 3.2137718623002]\n",
      "time stds  [0.0765578430701207, 0.02123633297924175, 0.14405166321102844, 0.07235070650392743, 0.32481346477102646, 0.7760303669028906, 0.38492108640163175, 0.6007434319114577]\n"
     ]
    }
   ],
   "source": [
    "# performance\n",
    "\n",
    "modelMean = []\n",
    "modelStd = []\n",
    "timeMean = []\n",
    "timeStd = []\n",
    "for m in models:\n",
    "    accs = []\n",
    "    times = []\n",
    "    for i in range(10):\n",
    "        [train_input1, train_input2, test_input1, test_input2, train_classes1, train_classes2, test_classes1, test_classes2, train_target, test_target] = load()\n",
    "        # does the data really load differently ?\n",
    "        start = timeit.default_timer()\n",
    "        train_model(m, train_input1, train_input2, train_classes1, train_classes2, train_target)\n",
    "        stop = timeit.default_timer()\n",
    "        acc = compute_nb_errors(m['model'], test_input1, test_input2, test_classes1, test_classes2, test_target)\n",
    "        accs.append(acc[0]) #maybe add the digit recognition accuracy\n",
    "        times.append(stop-start)\n",
    "    modelMean.append(statistics.mean(accs))\n",
    "    modelStd.append(statistics.pstdev(accs))\n",
    "    timeMean.append(statistics.mean(times))\n",
    "    timeStd.append(statistics.pstdev(times))\n",
    "\n",
    "print(\"acc means \", modelMean)\n",
    "print(\"acc stds \", modelStd)\n",
    "print(\"time means \", timeMean)\n",
    "print(\"time stds \", timeStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2abf0143b911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodelS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodelM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodelS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3257\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;31m# Make this warning show up first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mitems\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# optimized performance (to not load 10*nb models but only 10 times the datas)\n",
    "\n",
    "dixAccs = []\n",
    "dixTimes = []\n",
    "for i in range(10):\n",
    "    [train_input1, train_input2, test_input1, test_input2, train_classes1, train_classes2, test_classes1, test_classes2, train_target, test_target] = load()\n",
    "    accs = []\n",
    "    times = [] \n",
    "    for m in models:\n",
    "        start = timeit.default_timer()\n",
    "        train_model(m, train_input1, train_input2, train_classes1, train_classes2, train_target)\n",
    "        stop = timeit.default_timer()\n",
    "        acc = compute_nb_errors(m['model'], test_input1, test_input2, test_classes1, test_classes2, test_target)\n",
    "        accs.append(acc[0])\n",
    "        times.append(stop-start)\n",
    "    dixAccs.append(accs)\n",
    "    dixTimes.append(times)\n",
    "\n",
    "modelMean = []\n",
    "modelStd = []\n",
    "timeMean = []\n",
    "timeStd = []\n",
    "for m in range(len(models)):       # 'axis=m' not working \n",
    "    modelM.append(statistics.mean(accs, axis = m))\n",
    "    modelS.append(statistics.pstdev(accs, axis = m))\n",
    "    timeMean.append(statistics.mean(times, axis = m)))\n",
    "    timeStd.append(statistics.pstdev(times, axis = m)))\n",
    "    \n",
    "print(\"means \", modelM)\n",
    "print(\"stds \", modelS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(histories, x_label, y_label, line_labels):\n",
    "    losses = [hist['loss_history'] for hist in histories]\n",
    "    for l,n in zip(losses,line_labels):\n",
    "        plt.plot(l, label = n)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_names = [x['model'].__class__.__name__ for x in models]\n",
    "plotLoss(histories[:2] + [histories[4]] + [histories[6]], '#of epochs', 'loss', curve_names[:2] + [curve_names[4]] + [curve_names[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss([histories[7]] + [histories[5]] + histories[2:4], '#of epochs', 'loss',  [curve_names[7]] + [curve_names[5]] + curve_names[2:4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
